MoneroKon 2019 – Visualizing Monero: A Figure is Worth a Thousand LogsI usually like to start talks with introductions and acknowledgements. I'm Mitchell Krawiec-Thayer. Thank you again Sarang for the introduction. Also credited heavily for this talk is Neptune who is the cofounder and data curator of Noncesense Research Lab. The two of us have been working around the clock for the last couple of weeks trying to churn everything out. A lot of this research came together in the last week, slides in the couple of hours. Thank you so much for sticking with me.  Also, thank you Monero Research Lab—like my second home. If there is anyone from XMRChain, I'm sorry I kind of abused your API a couple of weeks ago. We set up our own private blockchain explorer now but I was kind of hard on your API when making plots, so thank you for the role you played in this presentation.  Oh, and thank you to Serhack.So the outline for this talk: motivation, intro, etc. And then I'm going to talk about three different heuristics for tracing Monero that also apply to other privacy coins. The motivation for this talk and the motivation for sharing these heuristics with the community is strictly to keep Monero users safe. That is always the beginning and end goal of my research. During this talk my goal is to inform best practices for users and also to inform best practices for software creators and guide the design of wallets that are compatible with how the reference is set up. In short, the aim is to design protocols that enforce best practices by identifying and preventing anomalous behaviors. Talking a little bit about fungibility and the Monero ideal, the goal is always to have 100% of transactions and outputs be effectively indistinguishable from each other. So essentially we would have a single anonymity pool. Quick side note: I am going to use the terms transaction and output somewhat interchangeably during this presentation because if you have a weird output your transaction looks weird and vice versa. So you can gloss over that. From a statistician’s point of view we actually have one big anonymity pool that contains most of the transactions. And then there are several smaller sets, I call them "anonymity puddles," that are subsets of transactions that don’t blend in with the rest. So today I’m going to talk about three different ones that are all around the order of a percent. And the good news is all of these can be fixed at the protocol level. So I will also be presenting possible solutions. Of course, I would never unilaterally make a consensus protocol change, so this is all just opening up discussions that we can have in the community over the next couple months.If you are using custom or common software, you are probably in the main pool, so don’t worry about this. I’m really just focusing on edge cases in this talk. Let’s do a little bit of basic introduction to transaction analysis. I’m making two simplifications here: One, just to make the chart followable, I’m using one in and one out transactions. Normally you have one or more inputs, and we believe all transactions should always have two or more outputs so it looks like you have a recipient and change. This actually isn’t implemented at the protocol level yet so there have been about 2,000 transactions with a single output, but hopefully that will be changed in the next upgrade. And then, I’m showing ring size three; at the moment ring size is 11, but it makes the diagram possible to follow.Let’s say this blue dot is a Monero output we have received, and—as a recipient or an external block chain explorer—I want to investigate where it came from. Because we have ring signatures it doesn’t just say, oh it hopped from here to here. There are actually three possible histories, three possible places it could have come from. Maybe I want to look another layer back—where did these three come from. Well there are three more histories. Then, where did these come from, etc., etc.  So this is the ideal of Monero. Any time you go to look at where something came from there are a whole bunch of possible histories and this just kind of fans out going backwards. So these blue circles represent the ideal where we have this 100% indistinguishable anonymity pool. Now I’m going to introduce red squares, which are the transactions or outputs that have distinguishing features, and there are many types of possible defects that can show up in privacy coins. One of them is when we had an anomalous ring size—you would have people using ring size of 40, 50, thinking they are being sneaky, but it just sticks out in the pool when people are using seven. This is fixed in version 8. Another one is the Tx_extra contents and metadata. So this has been discussed during the conversation around deprecating payment IDs. Neptune is currently doing an analysis that has turned up a lot of really funky stuff in Tx_extra, such as duplicate payment IDs, some really weird stuff that actually bypasses the length of the field—all kinds of strange stuff. Once we finish that up, it should be public soon.What I mentioned earlier was anomalous transaction structure, so if you have a single-output transaction, again, hopefully we will remove those in the next upgrade. One of them is anomalous fees, which I will talk about during the first portion of this presentation. This one actually applies not just to Monero but pretty much any privacy coin, CryptoNote and otherwise. Then I’ll talk about transactions that ignore the unenforced lock time. And then lastly I’ll talk about incorrect ring member selection in Act III.What I’m saying is there are a lot of different ways that a transaction could stick out and be a red square. What happens when we come across these? Well, If I have one of these red-square transaction and I look back I’m probably going to find a similar one further upstream, if nothing else because of change outputs. And, here, it probably came from the red one, but we don’t know, it’s one in three. What if I dig back a little further? Now I’m starting to see a chain. And of course occasionally you have just random ones that are picked up as decoys, but if you really start pushing back through the transaction tree and you see a string of these transactions or outputs with fungability defects you can start to statistically infer the true flow of funds. So this is the mental model that we will look at moving forward. And when I refer to anonymity puddles, I’m basically talking about where we have a bunch of these red transactions sticking out.Act I is on unusual fees. People who use the core software have probably seen this screen where you can pick a slow fee, a normal fee, a fast, or a fastest. What ends up happening there is Monero has a dynamic fee market—it’s really cool, I won’t go all the way into it.  But basically there’s going to be—based on transaction traffic, block size, whatever—a reference fee, and then you can take different multiples of that depending on if you are in a rush for your transaction or if you have plenty of time. So what you will see is that most users fall into one of these four bins, they have selected using the core software, for example, a normal fee.Now very quickly I just wanted to highlight that there are some unusual fees that show up. Here the x-axis is showing the fee that was attached to a transaction, and the y-axis is showing how many transactions used that fee. And this is showing all RingCT transactions since its introduction up through May 2019. And what we see is that the vast majority of users pay zero or a very small amount of fee. (Fun fact: there are actually two RingCT transactions that paid zero fee, but that is a whole other issue.) If we look at the same plot on a log-y axis, then we start to emphasize the little odd things that happen out on the long tail of the distribution. I just wanted to share this to note that there is someone who has paid 7-, 10- and 12-Monero fees. I’m not sure if that was on accident or if they were in a really big rush—I haven’t dug into that.Next we’re going to look at how fees have changed over time. I’m going to show you the x-axis being blocks that contain RingCT transactions and then the y-axis being the absolute fee in micromonero. And a couple of things pop out. First of all, we see that there are different fee levels. You have lowest priority, medium, and high priority. And most transactions showing up in these lines are probably using the core software…or one that has implemented the correct fee market. Does anyone know why there’s that drop off just before block 1.7 million?...bingo—this is exactly where bulletproofs were activated, and since transactions got smaller fees went down dramatically. I’m not sure if you can see it, but it’s cool that if you zoom in you can start to see the lower two bands creep in a little before the mandatory cutoff as people adopted an upgrade of their software early.Now we’re going to look at the first anonymity puddle. There is some particular piece of software that attaches a fee of exactly 0.002 Monero to every single transaction, and this makes a very small anonymity puddle. Out of 3.7 million RingCT transactions about 100,000 of them use this exact fee. That is unusual, and those transaction stick out if you have this red trace going through it.Next, I switched the color scale to a log axis so you can see a little bit more of what’s going on here. This is the same plot, but just emphasizing the low noise. You can see that we really don’t have this simple picture we would expect, just having low and medium transaction priority. A couple of things that jump out: some of the spanning is probably due to different size transactions, so if I have a two-input two-output transaction that I would attach a standard fee level to, that would be a certain amount of Monero, but if I have the same priority level on a two-in 10-out transaction it’s going to have a different absolute fee.Next, to deconvolute that, I’ve now switched the y-axis over to relative fee. This is micromonero per kilobyte of transaction size. The picture is pretty interesting. Again you can see where there are different priority levels, I think the lowest and the medium one. There is some fanning out at the end. I’m not 100% sure about this, I think that might be fee sniping. If the block is getting completely full or, say, 80% full of transactions paying fee priority two, and you want to get one of  your transactions in the next block you have a couple of options: you could pay fee priority two or you could pay effectively 1.1 and then you jump in line from everyone who is paying the single, one, priority. You speed up how fast you get in the next block without having to pay up to the next level.We also see some people who have hard-coded software with exact relative fees. So here is another anonymity puddle where the fee was specified out to eight significant figures, which is a little bit overkill. These are 22,000 transactions out of 3.7 million, so it is a very small anonymity puddle. Just to kind of draw your eye through the issue to realize how fractured our fees cause our anonymity pool to be, if you just start at the bottom of that white line and cut your way to the top, you pass through four, maybe five, different anonymity pools: the default ones, the static ones, the super high ones, all the outliers. I would say that is not ideal. This is all because we have these very high resolution many-significant-figure fees that leaks information. My proposal—a possible solution, there are others—is that transactions would only be valid if the fees are an integer power of two. I’ve taken all of the real RingCT transactions, so 3.7 million transactions, and then I’ve retroactively rounded it to the nearest power of two. Now what you see is that you still have a fee market. People can still pay more, pay less, depending on block size, depending on how fast they need to be in there. But we’ve now really limited how much you can allow your software to be fee fingerprinted. This could be applied to either the absolute fees or the relative fees—I don’t have any particular thoughts either way right now. And the funny thing is that this actually reduces transaction size because you are going from many significant figures to just specifying an integer.Conclusions from this part are that we have four separate anonymity pools based on the fees: 1) There is the correct reference pool where people have just selected priority level one, two, three or four. 2) Then we have people who have a fixed absolute fee, for example always 0.002 Monero, which we saw earlier. 3) We have people that have hard-coded a fixed fee per weight, for example 0.01 Monero per kilobyte. 4) And then we have outliers to the above three sets. This is all about partitioning the anonymity pool. If I can partition some out, then I am effectively also partitioning the other ones.One of my main recommendations is eliminating high precision fees. Again, it makes it smaller with less info leak. Just a very quick detour: fee fingerprinting can be combined with other heuristics. In fact, basically heuristic can be combined with any heuristic. It’s one of the tricky parts about this. One example is timing analysis. So going back to this plot, when I was originally pulling it down, I zoomed in on the last couple weeks. And, lo and behold, two things jump out. You have your low fee level, your default fee level, and then you have these transactions that are happening very periodically with a high fee. And I actually went through, looked at the transaction tree topology, and sure enough you can just trace right from one to the other. I wouldn’t even call it an anonymity puddle; it’s an anonymity drop. Just a general reminder to also be careful about periodic timing. For Act II, I’m going to look at juvenile ring members. For this, I need to do a brief introduction to how decoy selection works. Let’s say that I have a whole bunch of blocks from 2017 up through 2019 and I want to spend some fund that is the green dot. My wallet is going to go out and pick a whole bunch of decoys, which are keys that do not belong to me but I grab the public key and I mix it in when I construct the signature. So they’re going to take all of these—the true spend and the decoys—they’re going to mix them in the ring signature and then deposit the transaction as a new output. The only part that observers can see is this outside portion. They ostensibly don’t know what the true spend is. They can just see what went into the ring signature. One of the things you can do with that from an outside perspective is you can look at what is the youngest ring member. (Thank you XMRChain, I scraped like 400,000 signatures.) Most of them fall within a very young range. If we look at the three-month line, 99.7% of transactions have a very young youngest ring member. And then there is this weird outlier with 0.3% of transactions that use a different algorithm. Again, I’ve switched to a log-y scale so you can see a little bit more of what is going on. On the left, you see the correctly constructed transactions, and then on the right there are a couple of different anonymity pools. I’m not going to split them up here, but you can see that there are some odd things happening.One of the things that was interesting is we have a 10-block lock time, so the youngest ring member is going to be at least 10 blocks because that is when you can spend your Monero. And then let’s see what the distribution looks like there. Much to my surprise, there are people that are overriding the 10-block lock. That is, in the reference wallet, the core software considers your funds unavailable until 10 blocks—i.e., 20 minutes—have passed. 1.6% of transactions actually bypass that and have ring members that are even younger. This is a very small anonymity pool. It’s a very strange behavior. I scanned the transaction tree topology and a lot of times you can see this again, a hop every one or two blocks straight across. Switching to a heat map, I wanted to know, was this little spurt from a one-time event or is it constant? And what we see now, the x-axis is time, several weeks, and then the y-axis is, what was that youngest ring member? None of them should be less than 10. It should just be black below the “10” line. And you see that throughout we have had people making these juvenile transactions. Here it is on a log scale.My conclusion from these observations is that the vast majority of transactions—or the anonymity pool—follow this 10-block lock time that is in the reference wallet. A minority of ring signatures include members that are less than 10 blocks old, which really sticks out. My philosophy is that the protocol should enforce privacy-relevant reference issues. If it’s important enough that we code it into our wallet, we should also code it into our protocol. There are three options here. One is that we add that 10-block lock at the protocol level. So we would reject transactions that are younger than that. Another option to make it match would be to remove the 10-block lock in the reference wallet. Or there could be some compromise where we go to, say, five blocks but it’s also enforced in the protocol. My inclination right now is number one because there has not been research showing that lowering the confirmation time is safe, so that would be my conservative recommendation. There is a fourth option: we could keep the transaction that have juvenile ring members in the mem pool and not mine them until enough time has passed. That would be good for someone doing retrospective blockchain analysis. It would not be robust against an adversary that is running in our network. A quick note: this is unrelated to permitting 0-confirmation purchases. If you buy a t-shirt from me and I’m like, cool, five bucks—I’m not worried and walk away. That’s fine. That has nothing to do with protocol. Quick note: I think that 10 blocks was chosen arbitrarily. Is this optimal? I’m not sure. It is out of the scope of this talk. Let’s research it.Act III, egregious decoy selection. The standard best practice for selecting your decoys is to pick several of them from recently, and then have a couple further out. The logic behind this is that most outputs—we suspect, based on spend time analysis of other chains—churn relatively quickly and so you also want your decoys to be relatively recent. And you also want some long tails so that if someone has to spend an old output, they have cover for that. So this is the right way to go. It is really bad practice to use uniform random decoy selection. So if I just pick 11 random members over the course of history…Get a mental image of this, green dots are good, red dots are bad. It’s quiz time: Who thinks A is generated correctly? What about B, does that look right? What about C? What about D? OK. Pretty much everyone go that. A and D are wrong—or generated with a  different algorithm—and B and C are regular. My point here is that just because something is nondeterministic does not mean it is nonverifiable. You all just very intuitively did this. A quick way to make a statistical metric out of this is to use the median, which is convenient. In a set with 11 members, your median is going to be sixth oldest. If you look at the median on these, the ones that were generated correctly tend to have a median that is relatively close to today, and the ones that were generated using uniform decoy selection are typically much further out. This is not to scale—it is actually a much more dramatic difference than this. If we look at that median, back to what outside observers can analyze, median ring member age is the sixth ring. I’m going to use what I call the offset-corrected median age, and I’m going to ignore the length of time up to the first ring member. And that’s to cover delayed broadcast. I generate a transaction, I don’t have Internet access for a day, and then I broadcast it. If that offset is ignored, you can still do that.So let’s look at the offset-corrected median age. That’s the x-axis. The main thing we see is that because most people use the correct algorithm most of them are very short. 99% of people use the correct decoy selection algorithm. You can put a 500-day mark and see that there are a couple people doing strange things out there.  Once again, I won’t dig all the way into this, but you have the regular anonymity pool on the left, and you have several small anonymity puddles on the right. Just looking at it on a log-log scale, now the median age and the counts are in log scale. This big bump is transactions that were generated using the correct algorithm. It’s pretty clear, I think, at this point, even just intuitively, which ones we could rule out as being oddly generated.I really like heat maps—you may have noticed. Looking at how this evolves over time, the x-axis is height, equivalent to time. The y-axis is this offset-corrected median metric. Just to put some guides on this, the bottom row is one day, then one month, one year. You can see that the big yellow band in the middle is the main anonymity pool. You want your transactions to be in that anonymity pool. Anything that has a strange decoy selection, that’s out past a month, out past a year, is definitely not using the standard algorithm. So these ones out here that are 500 days old are very peculiar and there are some other heuristics that opens up—so we want to avoid that. The conclusions are that the vast majority are using a plausible distribution. Small anonymity puddles use distinctly irregular selection, often that’s uniform, but there could be other wonky things going on. I believe the offset-corrected median is a robust method of identifying the worst offenders, which are the biggest privacy leaks—so these ones that are like 500 days old.My recommendation is that the consensus protocol could reject transactions whose offset-corrected median age is more than some threshold. A very lenient threshold would be about 500 days, which is so absurd that it would never reject a properly constructed ring. We could actually, plausibly put a more strict standard, but I didn’t want to go down the rabbit hole of parameter selection during this talk—that’s a conversation we will have in the upcoming weeks and months.My closing thoughts, kind of high level. One, visualize your data, leverage your intuition. It’s really hard to stare at just a text dump, but if you can import it into Python and make a couple quick plots, you will have way more power in interpreting what you are looking at. My advice to privacy protocol engineers is enforce necessary best practices in the consensus rules. Don’t just hope that all devs will match the perfect reference implementation. It’s a complicated thing. There’s a lot to get right, it’s easy to get stuff wrong, and it would be helpful if the protocol actually rejected things that were wrong to help wallet makers debug, troubleshoot, and get their wallets working correctly. Privacy coin software developers, try to match the reference wallet. An approximation or a simplification like just grabbing random decoys can leak a surprising amount of information. It can be kind of insidious. You often don’t notice it until you visualize it.For users, use a community-vetted open source wallet. See the Monero sidebar on reddit. When in doubt use the core software from getmonero. And if you are curious you can look at your transaction on a block explorer. I have actually done that when trying a new piece of software, I’ll go take a peek at it and just look myself. Did it use the correct algorithm? Did it set a normal fee? All of that.In closing, first I want to thank Insight. I run a professional training program there to help professional software engineers, academic researchers, and hackers transition into a full-time career in blockchain engineering. And they actually sponsored me to come out here. So thank you very much. If you would like to be in our next cohort, applications are open I think for another week. But we’ll be running a full session, hands on and in person, next September. And also, Noncesense Research Lab, all the supporters there…much appreciated. Now I will open to questions. There’s my e-mail. And all these slides and code will be available at k2019.noncesense.org. I’ve uploaded the slides. I’m going to sanitize the code a little bit and then I’ll put that up in the next couple days. Thank you.Question from Audience: I’m curious as to who you think the worst offenders are. Is it wallets, exchanges, miners? Who do you think is actually doing this weird decoy selection or confirmation time?Answer: Good question. I don’t have any definitive answers. With regards to the fees, I could see that being a whole bunch of different parties. With regards to spending faster than 10 blocks, I haven’t the faintest. The last couple of weeks saw the order of 10,000 transactions, so I don’t think it is one person. I don’t know if it is some website, some exchange. I don’t know why an exchange would need to bypass that—that wouldn’t make sense. So I’m not sure. I’ve been digging around just doing analysis from the blockchain perspective. I haven’t done any matching back to real-world entities yet.Thank you much.