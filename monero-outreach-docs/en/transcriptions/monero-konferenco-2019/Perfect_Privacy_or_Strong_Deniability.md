Perfect Privacy or Strong Deniability?
Dr. Brandon Goodell, Monero Research Lab

Hi everyone.

I heard a story a long time ago, and I have no idea how to attribute this story to anybody, so if anybody can educate me about my own anecdote that would be very helpful. Rumour has it, years ago, someone asked a Google engineer about how good Google search was, and he said something like, "Well on a scale from zero to ten, and ten is like God's search engine, Google is a two and everybody else is a zero or a one".

I want to start my talk today with the idea, the proposal, that the best privacy currencies on the market right now are at a one out of ten, and that everybody else is a zero out of ten. So, when you watch this talk, please keep in mind that I'm referring to most cryptocurrencies out there, and in fact, I'm going to try my best to make this as clear as possible.

So, I'm here to talk about perfect privacy and strong deniability, because everybody can agree that perfect privacy is hard, but developing something that's like plausible deniability, that's a much easier problem. And, in fact, most cryptocurrency threat models and privacy profiles boil down to that of plausible deniability.

Here's a common example: we have somebody who buys something from an exchange, buys some Monero from an example, and then they go buy something from a vendor. And then the vendor deposits it directly back onto the exchange and cashes it out to dollars, because who wants to carry cryptocurrencies, or hold them - who wants to hold such a volatile asset? And so of course, Eve would have to be stupid to look at a transaction like this and see 8.675309 Monero came in and 8.675309 went out - what do I do, how do I link these, it's a mystery! It turns out if Eve aggregates this sort of approach over many many examples and many many customers, much like using Mitchell's approaches, Eve can do a good job of collecting a lot of information about what actually happened in these transactions.

In fact, everybody in this room, I hope, has a great deal of respect for privacy as a human right. There are issues involving privacy, from a 15-year-old hacker down the street who lives in his Mum's basement and wants to deanonymize you so that he can blackmail you. And then there's the state-level actor who wants to keep a surveillance eye on everybody, like China for example. And then there's somewhere in between where you have something like an exchange or a large-scale corporation that wants to be able to do targeted advertising to you. Or something a little not as bad as the extreme examples of the totalitarian nation, like a state that just wants to track money laundering for example. So there's a bunch of different situations in which privacy is important. And some of those are things that society rejects, like criminality. We reject criminality - if you're money laundering, you know, we have a problem with that generally as a society. But we also reject tyrannical regimes watching us. So there's something to be struck as a balance between these things.

Now, if we're talking about something like Eve watching these transactions, what we end up with is a diagram that's sort of like this. Forgive my beautiful diagram making skills, this is the only diagram in this talk that I actually made. 

Speaking of which, by the way, I want to thank Sarang for making the background slide of my talk; it's absolutely fantastic, it's gorgeous.

So anyway, Alice buys from Eve, goes purchases something from Bob, and then Bob deposits to Eve. So, arrows one and three. If Eve is an exchange, and Eve is keeping an eye on her transactions, she can deanonymize those pretty well, especially if she's a KYC exchange. Eve will learn all about what Alice's address and Bob's address is, and so since she knows about arrows one and three. She knows quite a bit about these transactions. In fact, the problem is, in a certain sense, you may ask why is Bob involved at all? Because Alice doesn't know she's interacting with Eve or Bob. And, in fact, if you reduce this down to something like 'Eve is the exchange and she's corrupted everything and she's watching you and she's also the vendor' and all that stuff, you have this weird privacy game where Eve hands Alice a coin, and then Alice hands a coin back to Eve, and Eve has to figure out where it came from.

Of course in a cryptocurrency network this is a stupid game, because if Eve controls all of the transactions except for Alice's, all she has to do is say, "Oh well, this came from a transaction that I didn't create; I'm Eve, I'm the other half of the network, so it must have been Alice's". So this privacy game isn't enough to even describe what goes on in cryptocurrencies. This is why we refer to this as the EABE problem so far in our conversations on Monero Research Lab.

Now, Mitchell's talk was about a couple of statistical signals that Eve can latch onto in order to deanonymize the network. Instead of looking at the statistical signals, I'm actually looking at the computational puzzle of drawing those red lines in Mitchell's talk earlier through the blue tree. I wanted to know exactly how hard it is for that little magnifying glass in the bottom of his talks. That's putting a lot of stuff under the hood. How hard is that magnifying glass to actually apply? And it turns out that it's easier than we hoped.

The transaction model in general for most cryptocurrencies is that you eat some keys and you spit out some keys. And the only way you can tell that this is valid is if you have some proofs along with some fees. Like signatures: signatures are proofs of knowledge. zk-SNARKs they're proof of belonging this large shielded pool. Similarly, almost every output-based currency can be sort of visualized this way, and this is actually where everything falls apart, from the very beginning of looking at keys in keys out, authorized by signatures, because what we can do is build a big graph that looks like this.

Okay, this is a Bitcoin example, or an Ethereum example, a transparent coin example. Keys X1 and X2 here are signing sigma1 and sigma2, and those two are being combined in a transaction to create an output Y1. Those are the first couple of dots on the top. X1 and X2 are spent to create Y1 and the authorization sigma1 and sigma2. And then Y1, Y2, and Y3 are spent in tau1, tau2 and tau3 to create Z. So the dotted lines are output relations and the solid lines are input relations. The flow of funds is really easy to track - you zigzag.

But what about privacy-respecting currencies? The idea behind some anonymity coin is to replace the solid edges with sets of solid edges, and you say, "well I don't know which one of these edges is solid". So we're going to replace the solid edges with a couple of dashed edges, each single solid edge turned into more than one dashed edge. In this example, this is a similar graph to Mitchell's because we have a ring size of three. There are three keys being used to construct each of these signatures. So on the left-hand diagram, we have keys X1, X2, X3; one of those must have been used to create sigma1, to create the key Y1, which is then spent with Y1, Y2 and Y3 in tau, creating Z. That's the one on the left. So there's a clear flow of funds. X1 got spent in sigma, and then there's the dotted line and that was used to be spent in tau, and that's another dotted line, so you can zigzag. On the other hand, on the right-hand side, we have a conflicting transaction history; sigma and tau have nothing to do with each other on the right hand. There's no flow of money here, tau is signed by Y2. The output of sigma was Y1, so there's no flow.

So, what do we do with all of this? We play a game called matchmaking or matching. This is actually the sort of depressing part about this talk. The first thing that you learn in graph theory, in a graph-theoretic class, is the matching game. It's one of the oldest solved problems. It's used in hardware design and in hardware analysis all the time. It's, like, the most optimal algorithms today that I'm going to be presenting here, or at least some variant of them, they were created in the early seventies or late sixties. All right, so this is a solved problem. Matching is not hard. Going from a diagram that looks like this with all dashed edges, to a diagram that looks like this with just solid edges, that's computationally extremely easy, and that's what I'm talking about today.

So, how does E decide which edges are supposed to be solid? That's really her question. Mitchell's talk revealed a couple of different heuristics that can be used to be leveraged to figure out which edges are supposed to be solid. Now, what happens if somebody gets really really eager with it and they start to formalize these heuristics so that you can apply rigorous statistical tests instead of following your intuition and graphing it? No offense - no no no, Mitchell gave a fantastic talk which ended with fantastic recommendations, and the images in his talk are how he came to his conclusions, and this is like a human visual system thing, right; we're visual processing units. And in the end, a statistical processing unit - that's not what humans are good at, right? So what we want to do is we want to formalize these visual intuitions that we have and turn them into rigorous statistical tests that have some power and meat to them, Okay. So what do we do?

Let's start with the easiest example. Throughout most of this talk, I'm only going to be speaking about timing. So, all of the information in Mitchell's talk is actually plug-and-play with my talk, you just replace the phrase 'timing' or 'age' with one of the other heuristic things that Mitchell was talking about like fees. In fact, fees can be used to estimate age. So, fundamentally, back in the day, we had, I think it was in January of 2017 or January of 2016, it was a January, the Monero-link paper came out describing the traceability within Monero. And Andrew Miller, one of the authors of that paper, proposed the guess-newest heuristic, and Mitchell already described this to you - if you have a bunch of transactions, and the first one is usually the true spender, then you can just go through and guess: true spender, true spender, true spender. And in fact, if the ring signatures are all chronologically ordered, and they are, then you don't even need to load the whole ring, you just load the first key in the ring and then move onto the next ring.

So how do we formalize this? What we can do is kind of get a grip on what is driving the guess-newest heuristic is that the wallet distribution is picking too many old outputs and not enough new outputs. So there's a gap between the wallet distribution and true behavior. Now we can all argue about whether or not ground-true behavior really exists, but that's way beyond the scope of this talk. But what we can do is hypothesize something. Like f0, f0 is some hypothetical probability mass function that is deciding the probability that you wait a certain period of time before you spend a coin. And if I have an idea of what your spending behavior is, for example, the periodic graph that Mitchell showed earlier that had bright dots that were spread out. That could have been a magazine subscription. It was like every week or every month or whatever. So if we have a hypothesis about that, this informs what our f0 is. We come up with some distribution that has some periodicity behind it, and then we apply some approach drawing lines, and then we come up with a better distribution f hat. Then we do this over and over again, over many many customers, and we sell our data to Facebook or the FBI. And we hope that Amanda's talk earlier about how data is a tertiary or a secondary market saves us as Monero users. That's not an acceptable situation, especially if our design philosophy is Monero safety first, users first. Some people use Monero for life-saving reasons, and if we are coming across problems like this, then we need to make it very clear to people what the capabilities of our software are. And this also goes for every other privacy cryptocurrency, by the way, before I switch over, let me go back, just sit down and distract you guys with math. 

Every other private cryptocurrency is having similar issues with this linkability thing, but every single private cryptocurrency says, "We're the private one, those other guys are jerks". So I want everybody here to take away something, and everybody who's watching online right now, to take away - if I'm going to have everybody take away something - it's going to be threat model to keep in mind. You may not be able to use something like Monero or Zcash to protect yourself if your life depends on it. This is a fact that is a very uncomfortable fact for a lot of people in our community. When somebody says it in a news article we get upset, but we are super happy to talk about how Zcash is not safe to use if your life is on the line. So, as far as that goes, I want to make sure that everybody in the room is clear on the fact that I'm talking about all currencies, and that we're at a one out of ten. That's the state of private cryptocurrencies today, to steal another talk title.

To be really really specific for the math nerds in the audience, the question might be how do you really go about drawing these lines? And that's the remainder of this talk because I'm a math guy. The really easy way is to take this big graph, that I showed you on a previous line, and we put a weight on each edge, and then we try to find a matching on the graph that maximizes the weight. And this is what I meant on a previous slide, when I asked, "How does Alice decide which edges to include?" I put a weight on each edge and I say, "I want the heaviest possible choice". So what do we do, looking at timing, age of outputs, what we can do is assume independence between the outputs. And we can, oh, there's a spelling error, likely is it. That the edge Xi goes to sigma. 

Anyway, so we define the likelihood that an edge should be included in the solid matching, in the usual way by assuming independence. For the statisticians in the audience, this is an obvious thing to do, we take the product of the probability functions. If we want log-likelihood we would take the logarithm of the probability functions, and that means just adding them up. The thing is [laughter], here's the bad part, fw is the wallet software distribution, so you can go and look up in the code exactly how to compute fw. f0 is your hypothesized information. So, the vast majority of the information that is stored in the ring signature a1 through an - in terms of the ages anyway - the only one, ai, that's the true signer, only one of those things is using unknown information. The rest of this product, we know. All of it. So there's really only one little missing piece of information. We may not know which one of these ai's are missing but we know that only one piece is missing and this is really powerful.

Before we continue, I can see now why you were saying that this was a slightly out of context slide. If one of you is sitting in the audience and you're thinking, "Gosh this statistics is really hard, you'd have to be a mathematician or statistician to do this, you have domain knowledge, how do we gain this domain knowledge? And how do we protect ourselves?" Well, the answer is, if you have domain knowledge you can almost always protect yourself. I mean, everybody remembers the show Dexter, you have the blood spatter analyst guy who happens to be a serial killer, and he uses his years and years of education and blood spatter analysis in order to hide the fact that he's been murdering people for years.

If we're going down that road, what we're talking about is using statisticians to very cleverly construct a bunch of evidence that makes it seem like they're not the person who did it. And, in my mind, that has a bunch of different flaws in it. For one thing, you can't use this in a court of law. You can't say, "Well, I'm innocent because somebody could have faked that evidence". That blood splatter over there could have been totally faked by Dexter down the street, sure, but that doesn't make it a plausible legal defense.

If it takes special domain knowledge to get away from this, and if it's really fast to do, then what somebody can just do is like hire a couple of Ph.D's. Give them access to an Amazon cloud service, and just be like,"Hey guys, go at it, figure out the Monero blockchain, figure out the Zcash blockchain; oh and by the way since heuristics from multiple sources can be combined for more powerful heuristics, you may as well use information from the Monero blockchain on the Zcash blockchain." And then what's going to happen is that these guys are going to build some algorithm, and they're going to use the Hopcroft-Karp algorithm to find a maximal matching and then they're going to use a similar algorithm to find the heaviest matching.

And these are all a bunch of numbers that might distract the people in the audience who aren't related - or numbers, letters - that might distract the non-mathematicians in the audience, but in that graph that I had earlier: E is the number of edges, that's the lines, and V is the number of dots. So, when I say big O of E times the square of V, I mean I take the number of edges, I take the square root of the number of keys and I multiply them together and that's how long it's going to take. But it's parallelizable, so I can just do it in ten cores and take one-tenth of the time or I can do it in 100 cores and take one one-hundredths of the time. So these numbers can be made as small as they want. And this is why I say that every cryptocurrency has this problem right now. If you're a big fan of the Zcash sapling pool, and you're like, "Oh, cool, the sapling pool, it's like they got rid of the problems with the trusted setup, man". Yeah, but, you still have a nice small pool, and it takes like almost no time whatsoever to guess a transaction history that seems statistically plausible. Which leads us to plausible deniability. In Monero by the way, the number of edges we have here is our ring size r times the number of keys, so this even reduces further to this more reduced equation. So if I, if I double the number of keys in the blockchain, it less than quadruples the amount of time it takes the deanonymize these things, that's what that V to the 1.5 means.

What does Eve do? She hypothesizes some f0, and then she goes and gathers some data. She computes an optimal matching, and that's the heaviest matching, and then compares to her known solid edges. And by the way, E is a nice brilliant exchange who's been keeping track of all of her user information, so she knows a lot of true edges. And then she can use that information as a validation set to form a better hypothesis f0 hat. And then the exchange iterates this process over and over again and aggregates over many users, or with many data sets. And this is what I was hinting at in the last slide is that, if I can deanonymize the Zcash chain in this way, then I can use that information to inform my choices about which edges should be included in the Monero blockchain and vice versa.

So, I really struggled for a while with the title of this talk. I was considering calling it "We all sink or swim together" because if you are using the Zcash blockchain irresponsibly, and then using the Monero blockchain, you are bringing that over to the Monero blockchain. And if I use the Monero blockchain using a unique ring size of 58675309 and paying weird fees, like rational fees or irrational fees, then what's going to end up happening is you're going to be deanonymizing everybody, and every single time you step on a new blockchain you're bringing that dirty data with you. 

Where's the deniability come in? Now, in my graph, earlier-- in the previous slide, I mentioned r was a ring size and E was the number of edges, by the way. So how many matchings are there really, if I picked one randomly out of aether? There's this weird number r minus 1 to the r minus 1 divided by r to the r minus two all raised all to the n, and this is by a mathematician named Schrijver who's had an enormous number of papers in the graph theory world. And now, this is what I mean by this: if I did one divided by that number, I would get something that is negligible. Now, negligible in the cryptography world is a great thing to have, because it means that it is really unlikely that something becomes a problem. If I pick a single matching out of a massive, massive pool and I have one divided by this number probability of being correct, then what I'm going to end up with is I'm probably not right. For most choices of r and n any way. I can pick a big enough r and n so that I'm almost certainly never going to be correct. And this is one of the things about cryptography that we really like - is finding these negligible things to create security parameters out of.

But, so now the question is: if this Eve, this exchange, picks a random matching out of the aether and then tries to accuse one of their customers of doing something wrong, or much more prosaically if they try to take this matching and then sell you something, using targeted advertising that you don't really want because you're not really a member of the demographic that they tagged you for, then their probability of being correct is one divided by that number. Roughly, at least best case. So, Eve, the exchange can't just find any old matching at random and just guess that this is the transaction history, they have to do this waiting thing. But the inadvertent side-effect of this number means is that there's almost always an alternative history that you can point to that exonerates you.

Or, so for example, in the Target example. I love Target because a couple of years ago Target predicted this teenage girl was pregnant before she had told her family, and then they started sending coupons to her house. Then her Dad got really mad. And this is not something that really is happening in our surveillance capitalism society very often yet, but if you had a system like this, you could be like, "This transaction history says I belong in this demographic over here" and, "this transaction history says I belong in this demographic over here", and, "this transaction history says I belong in this demographic". Why are you selling me bonsai trees? Like, dude, "I'm a 60-year-old white woman in like Texas, I can't keep a bonsai tree alive to save my life, why are you sending me this?" And so the idea is that there are so many alternative histories that are so close to the best guess that the exchange can generate, that you can always point at something that seems to give a different impression. And this is what we call plausible deniability.

And I think I actually just went over this slide. This brings up an important question: if I have this many alternative histories available, most of which don't implicate me, how much evidence is necessary for like a reasonable person to draw a conclusion? And the answer varies according to your definition of reasonable. Okay, so a couple of examples that we've already gone over. Should corporations even attempt to target advertising with so many self-consistent alternatives? Isn't it a waste of time? On another track, how many false negatives are they throwing their advertising dollars at like the Target example? Should law enforcement even bother with evidence that can be plucked from the system that has alibis built into it? I'm not so sure about any of these things, and these all address different threat models. Some of which are criminal, some of which are dealing with tyrannical nations, some of which are dealing with Target trying to sell you something that you don't really want.

So, this actually leads me to the very end of my talk, which is an example I used in a lot of classes back when I was teaching the false positive paradox. If I have a test that's really really accurate, like 99.99%, and it only is detecting a disease that occurs in like one in ten million people or one in 100 million people. Ten to the eighth is 100 million people, right, yeah, 100, 100 million people. Then you end up with 1000 false positives for every single true positive. This is what's called the base rate fallacy, and every single first-year doctor learns this in medical school, because if you apply a naive cancer test to somebody and you come back and you're like, "Oh, you tested positive". Well, you might want to test again, because 1000 to one says I'm still not sick, right? So this is something we discuss a lot in things like engineering and medicine. It's not something that I've heard discussed much in cryptography or cryptocurrency so far.

Now one thing that we use to get around this problem is to look at the statistical power of a test. Instead of looking at like the accuracy of 99.9%, we look at the statistical power and we define that very rigorously. And it's a fact that as the ring size of Monero increases, the power of these tests goes to minimum. It's also a fact that something that is at minimum, like a totally shielded pool, is probably going to be the best possible performance we can expect. These are two facts. We also have the fact that the ring size is at 11, and that these other examples have ring sizes in the millions. Right, if you look at a zk-SNARK as a ring signature on the entire set of keys in the blockchain - which is not a correct way of looking at it - but if you look at the anonymity set as that then what we end up with is Monero is here and Zcash is over here, and as ring size gets bigger we approach that anonymity performance. Of course, what I'm sweeping under the rug is the transparent pool.

Here's what we generally get - and by the way thank you again for Mitchell for making these figures, running a conference is busy work. So, the power of this test is going to drop as the anonymity set size increases. We start with a minimal anonymity set size which is probably like one, like Bitcoin, you know exactly who signed what in Bitcoin. That has a 100% power test associated with it. And as ring size increases, out here we might have something like Pirate Chain, which is new enough for me to regret mentioning it in public. But it looks cool, in fact, it has no transparent pool and it's using the sapling parameters, and so out here you have this massive massive anonymity pool. Over here you might have something like Zcash, or maybe Zcash is over here. Somewhere in between, you're going to have Zcash and Monero. And is not clear to me, where Zcash or Monero lay in this line. And so, this every single adversary that you are going to be facing, every single threat model that you have to deal with, there's going to be some threshold P star that they can't tolerate lower power than that. For example, if I'm trying to convict somebody, like the worst criminal in history, I'd better be sure because if I go to court and I am not sure, I'm going to have a really, let's see here-- yeah, if I go to court and I am really not sure then I might end up letting a criminal free and because of double jeopardy they're free forever. So, we want a really high power if we're law enforcement and we're trying to sue people. So we're up here.

On the other hand, if you're Target and you're just trying to do advertising dollars and that's the cost of losing is not like letting a murderer on the street, but just like a couple of advertising bucks, then you can tolerate a much lower power. So we actually have a graph that looks something like this.

An adversary with high standards can tolerate a ring size that is no bigger than here. An adversary with medium standards can tolerate a ring size about here. An adversary with really low standards can get away with linking transactions with a huge ring size. So in this graph, red means we should increase our ring size, and green means we're already good enough and we increase our ring size that means that we're wasting space and time.

So, in the end, here's the conclusion. Every privacy-respecting currency as it stands is at a one out of ten in terms of privacy. Every other cryptocurrency is at a zero out of ten. Privacy-respecting currencies can only provide plausible deniability. No such thing as perfectly anonymous currency. If you're using Zcash but the feds are physically tracking you in person, it doesn't matter that you're using Zcash because they watched you buy or pick up from the mail whatever it was that you bought. On the other hand, if you're being tracked by Target, again there's no such thing as perfectly anonymous. Target can probably buy data on you from also Walmart. And then they use that to leverage against you. So no matter what, you're not going to get much other than plausible deniability. As anonymity set size increases, the claims of plausible deniability get stronger, and we tap out at some maximum level, but we should probably stop at some level that we consider to be good enough.

But, for sufficiently large enough anonymity set size-- Ugh, I regret this final line, I regret this final line. Remove the words 'default-on' and 'opt-in' from this sentence. For sufficiently large anonymity set size, small anonymity sets might perform large sets. And what I mean by this, is when we're talking about transparent pools. If you have small anonymity sets that is default-on and there is no transparent pool, I suspect that there is, in fact, a sweet spot. On the other hand, if you're past a certain point, but you're still using transparent pools, you're actually knee-capping yourself. But, this is all preliminary results that I do not yet have statistical numbers for. I've been working on simulations, I've been working on simulations while organizing this conference, so I didn't get them done in time. I didn't know I was speaking until about 4 days ago.

So, having said all that, I really just want everybody to walk away from the criminals in the audience, to the revolutionaries against nasty tyrannical regimes in the audience, to everybody would just doesn't want Target to know their purchasing power - that plausible deniability is all you can really expect out of most of these currencies. Anybody who's trying to sell you anything else is trying to sell you a bridge.

We probably have time for just one or two quick questions, before the last session.

**Audience member:** So, because of what you said about the forensic analysis which is possible across multiple blockchains, do you think that the Monero community should come to consensus about outlawing cross-chain atomic swaps between Monero and Bitcoin until Bitcoin gets its act together?

That's not a question I was anticipating.

**Audience member:** That's why I'm here for.

Short answer, no. Long answer is it's complicated. And the reason is because banning anything on the protocol level can be wildly dangerous when we're talking about currencies in general. Exchanges are not exactly the point of money, but without exchanges, you have no liquidity, no local liquidity, and you end up with a problem in Venezuela that Jamal was talking about earlier. The short answer is if you ban that, I'm not sure if you can really -- oohh I was going to say a statement I disagree with. I don't know, I'll leave it at that.

Any other questions, before...

**Sarang:** I have a quick one. So you talked about there probably being a sweet spot in terms of anonymity set size and that that depends a lot on the power of your adversary. So, just on the spot, what is that number, do you know what it is? Do you have an order of magnitude estimate for it?

42. No. So, the first diagram that Mitchell showed was like a three-ary tree, because it's splitted into 3 branches at every node. And a tree like that, which is like the idealized case, it should be like - you have exponential growth of three to the n, and in those sorts of examples I've seen numbers as low as like 23 for ring sizes that seemed to be sufficient against reasonable models. On the other hand, that's an idealized model, and in the Monero blockchain, this tree can't grow forever. Eventually, it starts to overlap onto itself because there's only a finite number of nodes. And in the end, it's not clear. But, I personally advocate a slightly larger ring size at all times. 


