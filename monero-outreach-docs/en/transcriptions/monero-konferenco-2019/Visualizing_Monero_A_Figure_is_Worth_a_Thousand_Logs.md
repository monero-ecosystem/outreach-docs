# Dr. Mitchell Krawiec-Thayer  
_Visualizing Monero: A Figure is Worth a Thousand Logs_  

Mitchell Krawiec-Thayer (a.k.a. “Isthmus”) is the Decentralized Consensus Lead at Insight Data Science, a Monero Research Lab contributor, the editor of Mastering Monero, the founder of Noncesense Research Lab, and a hobbyist chess player & bread baker.  

**Visualizing Monero: A Figure is Worth a Thousand Logs**  
_Dr. Mitchell Krawiec-Thayer, Insight Data Science_  
[youtu.be/XIrqyxU3k5Q](https://youtu.be/XIrqyxU3k5Q)  

_**Abstract**_ 

Monero’s approach to privacy relies heavily on ensuring that all transactions are indistinguishable, since any patterns visible to an outside observer can be leveraged for blockchain analysis and transaction linking. Mapping the blockchain history to human-interpretable visualizations is a powerful tool for privacy coin research, since potential heuristics that would be challenging to identify from log files are intuitive to spot as visual patterns or clusters corresponding to information leaks. Consensus-level prevention of identifying features (e.g. custom ring sizes - fixed in v8) is paramount, due to the inherent threat of retroactive deanonymization, statistically-noisy change output traces, and combinable heuristics. I’ll introduce the basics of transaction tree analysis and key tools from the exploratory data analysis toolkit (histograms, heatmaps, and more). Together, we’ll leverage these visualizations to intuit ongoing information leaks and mitigation strategies for the next upgrade. 

_**Transcription**_ 

I usually like to start talks with introductions and acknowledgements. So, by way of an introduction, I'm [Mitchell Krawiec-Thayer](https://github.com/Mitchellpkt). Thank you again Sarang for the introduction. Also credited heavily for this talk is [Neptune](https://github.com/neptuneresearch) who is the co-founder and data curator of [Noncesense Research Lab](https://noncesense-research-lab.github.io/). The two of us have been working around the clock for the last couple of weeks trying to churn everything out. A lot of this research came together in the last week, slides in the last couple of hours. So, thank you so much for sticking with me.  Also, thank you [Monero Research Lab](https://www.getmonero.org/resources/research-lab/) - my second home, enjoying Konferenco. And then lastly, if there is anyone from [XMRChain](https://xmrchain.net/), I'm sorry I kind of abused your API a couple of weeks ago. So, we set up our own private blockchain explorer now but I was kind of hard on that one making pots for this graph, so thank you for the role you played in this presentation. Oh, and Serhack for helping out with infrastructure. 

So the outline for this talk: really quickly motivation, intro, etc. And then I'm going to talk about three different heuristics for tracing Monero, the fees actually applies to other privacy coins. 

Yeah, so I will just move through it. Where do I point this, is it this way? Okay, cool. 

So the motivation for this talk and the motivation for sharing these heuristics with the community is strictly to keep Monero users safe. That is always the beginning and end goal of my research. So during this talk my goal is to inform best practices for users, hopefully there's [inaudible] for you and then also to inform best practices for software creators and designing wallets that are compatible with how the reference is set up. So, in short, the aim is to design protocols that enforce best practices by identifying and preventing anomalous behaviors. 

So talking a little bit about [fungibility](https://www.getmonero.org/resources/moneropedia/fungibility.html) and the Monero ideal, the goal is always to have 100% of [transactions](https://www.getmonero.org/resources/moneropedia/transaction.html) and outputs be effectively indistinguishable from each other. So essentially we would have a single anonymity pool. Quick side note: I'm going to use the terms transaction and output somewhere interchangeably during this presentation because if you have a weird output your transaction looks weird and vice versa. So you just kind of can gloss over that. Now from a statistician’s point of view we actually have one big anonymity pool that contains most of the transactions. And then there're several smaller, I call them "anonymity puddles," that are subsets of transactions that don’t blend in with the rest. So today I’m going to talk about three different ones, all around like order of a percent. And the good news is all of these can be fixed at the protocol level. So I will also be presenting possible solutions for these. Of course, I would never unilaterally make a [consensus](https://www.getmonero.org/resources/moneropedia/consensus.html) protocol change, so this is all just opening up discussions that we can have in the community over the next couple months. 

So just for noone freaks out, if you are using custom or common software, you are probably in the main pool, so don’t worry about this. I’m really just focusing on edge cases in this talk. 

So let’s do a little bit kind of basic introduction to transaction analysis. So I’m making two simplifications here: One, just to make the chart followable, as I’m using one in and one out transactions. Normally you have one or more inputs, and we believe that all transactions should have two or more outputs so that it looks like a recipient and [change](https://www.getmonero.org/resources/moneropedia/change.html). This actually isn’t implemented at the protocol level yet so there've been about 2,000 transactions with a single output, but hopefully that will be changed in the next upgrade. And then, I’m showing [ring size](https://www.getmonero.org/resources/moneropedia/ring-size.html) three; at the moment ring size is 11, but just makes the diagram possible to follow. 

So let’s say this blue dot is a Monero output that we've received, and - as a recipient or an external blockchain explorer, either one - I want to investigate where it came from. So because we have [ring signatures](https://www.getmonero.org/resources/moneropedia/ringsignatures.html) it doesn’t just say, "Oh it hopped from here to here". There's actually three possible histories, three possible places it could have come from. So maybe I want to look another layer back - where did these three come from? Well, there are three more histories. Where did these come from, etc., etc.  So this is the ideal of Monero, is, any time you go to look at where something came from there are a whole bunch of possible histories and this just kind of fans out going backwards. So these blue circles represent the ideal where we have this 100% indistinguishable anonymity pool. Now I’m going to introduce red squares, which are the transactions or outputs that have distinguishing features, and there's many possible types of fungibility defects that can show up in privacy coins. So one of them is when we had an anomalous ring size you would have people that using ring size, 40, 50, thinking that they are being sneaky, but it just sticks out in the pool when everyone is using seven. This was fixed in version eight. 

Another one is the transaction extra contents and metadata. So this has been discussed during the conversation around deprecating [payment IDs](https://www.getmonero.org/resources/moneropedia/paymentid.html). And then also Neptune is currently doing an analysis that has turned up a lot of really funky stuff in transaction extra, such as duplicate payment IDs, some really weird stuff that actually bypasses the length of the field - all kinds of strange stuff than once we finish that up should be public soon. 

What I mentioned earlier is anomalous transaction structure, so if you have a single-output transaction, I can, hopefully, will remove those in the next upgrade. And then one of them is anomalous fees, which I'm going talk about during the first portion of this presentation. This one actually applies not just to Monero but pretty much any privacy coin, both [CryptoNote](https://cryptonote.org/whitepaper.pdf) and otherwise. Then I’ll talk about transactions that ignore the unenforced lock time, in Act two. And then lastly I’ll talk about incorrect ring member selection in Act three. 

So what I’m saying is there's a lot of different ways that a transaction could stick out and be a red square. So what happens when we come across these? Well, and if I have one of these red-square transactions and I look back I’m probably going to find a similar one further upstream, if nothing else because of change outputs. And, okay so, they probably came from the red one, but we don’t know, it’s like one in three. What if I dig back a little further? Okay, so now I’m starting to see a chain. And of course occasionally you have just random ones that are picked up as decoys, but if you really start pushing back through the transaction tree and you see a string of these transactions or outputs with fungability defects you could start to statistically infer the true flow of funds. So this is kind of the mental model that we're looking at moving forward. And when I refer to anonymity puddles, I’m basically talking about where we have a bunch of these red transactions sticking out. 

So Act one is unusual fees. So people who use the [core software](https://www.getmonero.org/downloads/) have probably seen this screen where you can pick a slow fee, a normal fee, a fast, or a fastest. And what ends up happening there is Monero has a [dynamic fee](https://github.com/JollyMort/monero-research/blob/master/Monero%20Dynamic%20Block%20Size%20and%20Dynamic%20Minimum%20Fee/Monero%20Dynamic%20Block%20Size%20and%20Dynamic%20Minimum%20Fee%20-%20DRAFT.md) market - it’s really cool, I won’t go all the way into it.  But basically there’s going to be - based on transaction traffic, [block](https://www.getmonero.org/resources/moneropedia/block.html) size, whatever - kind of a reference fee, and then you can take different multiples of that depending on if you are in a rush for your transaction or if you have plenty of time. And so what you'll see is that most users fall into one of these four bands, they've selected using the core software, a normal fee. 

Now very quickly I just wanted to highlight that there's some unusual fees that show up a little bit. So if you look at this plot, the x-axis-- sorry I'm used to walking so let me figure it out how to introduce plots without-- So the x-axis is showing the fee that was attached to a particular transaction, and the y-axis is showing how many transactions used that fee. And this is showing all [RingCT](https://www.getmonero.org/resources/moneropedia/ringCT.html) transactions since its introduction up through May 2019. And what we see is that the vast majority of users pay most zero or a very small amount of fee - fun fact: there are actually two RingCT transactions that paid zero fee, but that's a whole other issue. If we look at the same plot on a y-axis or log-y axis, then we start to emphasize the little kind of odd things that happen out on the long tail of the distribution. And I just wanted to share this to note that there is someone who has paid 7, 10, and 12 Monero fees. Not sure if that was on accident or if they were in a really big rush - I haven’t totally dug into that. 

So next we’re going to look at how fees have changed over time. So I’m going to show you the x-axis blocks that contain RingCT transactions and then the y-axis is the absolute fee in [micromonero](https://i.stack.imgur.com/Xg7U6.png). And a couple of things pop out. So first of all, we see that there's different fee levels. And so you have where there's the lowest priority, medium-high priority - and most transactions showing up in these lines are probably using the core software - or one that has implemented the correct fee market. 

Does anyone know why there’s that drop off just before block 1.7 million? Bingo, so this is exactly where [bulletproofs](https://eprint.iacr.org/2017/1066.pdf) were activated, and since transactions got smaller the fees went down dramatically. And I’m not sure if you can see it, but it’s actually cool that if you zoom in you can start to see the lower two bands creep in a little bit before the mandatory cutoff as people adopted an upgrade of their software early. 

So now we’re going to look at the first anonymity puddle. There is some particular piece of software that attaches a fee of exactly 0.002 Monero to every single transaction, and this makes a very small anonymity puddle. Out of, what is that, I guess 3.7 million RingCT transactions about 100,000 of them uses exact fee. So that's a little unusual, and those transaction kind of stick out if you have this red trace going back through it. 

I switched the color scale to a log axis so you can see a little bit more what’s going on here. So this is the same plot, but just kind of emphasizing the low noise. You can see that we really don’t have this simple picture we would expect, just having low and medium transaction priority. A couple of things that jump out: is some of the fanning is actually probably due to different size transactions, so if I have a two-input two-output transaction that I would attach a standard fee level two, that's going to be a certain amount of Monero, but if I have the same priority level on a two-in ten-out transaction it’s going to have a different absolute fee. 

So to kind of deconvolute that, I’ve now switched the y-axis over to relative fee. So this is micromonero per kilobyte of transaction size. And the picture is pretty interesting. Again you can see where there's kind of different priority levels, and I think that's the lowest and the medium one. And then there's some fanning out at the end. I’m not 100% sure about this, I think that might be fee sniping. So if you think about it if the block is getting completely full or, say, 80% full of transactions that are paying fee priority two, and you want to get one of your transactions in the next block you have a couple of options: you can either pay fee priority two or you could pay effectively 1.1 and then you jump in line from everyone who is paying the single, one, priority. So you've basically sped up how fast you get included in a block without having to pay up to the next level. 

Now the last kind of puddle like this that I showed was on an absolute fee but we also see some people that have hard-coded software with exact relative fees. So here is another anonymity puddle where the fee was specified out to, I guess that's like eight significant figures, which is a little bit overkill. And these are 22,000 transactions again out of 3.7 million, so it's a very small anonymity puddle. And just to kind of draw your eye through the issue and realize how fractured our fees cause our anonymity pool to be, if you just start at the bottom of that white line and cut your way to the top, you pass through like at least four, maybe five, different anonymity pools: so the default ones, you have the static ones, you have some super high ones, you have all these outliers. So that's I wouldn't say not ideal. And this is all just high-- it's because we have these very high resolution many-significant-figure fees that we wouldn't have without all this information leakege or the ability to leak this information. 

So my proposal - a possible solution, and there are others - is that transactions would only be valid if the fees is an integer power of two. And so what I’ve done here is I've taken all of the real RingCT transactions, so 3.7 million transactions, and then I’ve retroactively rounded it to the nearest power of two. And now what you see is you still have a fee market. People can still pay more, pay less, depending on block size, depending on how fast they need to be in there. But we’ve now really limited how much you can allow your software to be fee fingerprinted. This could be applied to either the absolute fees or the relative fees - I don’t have any particular thoughts either way right now. And the funny thing is that this actually reduces transaction size because you are going from many significant figures to just specifying an integer. 

So kind of conclusions from this part are that we have four separate anonymity pools based on the fees: There is the correct reference pool where people have just selected priority level one, two, three or four. Then we have people that have fixed absolute fee, for example always point 0.002 Monero, which we saw earlier. We have people that have hard-coded fixed fee per weight, for example 0.01 Monero per kilobytes. And then we have outliers to the above three sets. This is all about partitioning your anonymity pool. And so if I can partition some out, then I am effectively also partitioning the other ones. 

So one of my main recommendations is eliminating high precision fees. So again, makes it smaller, less info leak. And a just a very quick detour: fee fingerprinting can be combined with other heuristics. And in fact, basically any heuristic can be combined with any heuristic. It’s one of the tricky parts about this.

One example is timing analysis. So going back to this plot, when I was originally pulling it down, I zoomed in on the last couple weeks. And, low and behold, I see two things that jumped out. So you have your low fee level, your default fee level, and then you have these transactions that are happening very periodically with a high fee. And I actually went through, looked at the transaction tree topology, and sure enough you can just trace right from one to the other. So this I wouldn’t even call it an anonymity puddle; it’s an anonymity drop. So just kind of a general reminder to also be careful about periodic timing. 

So Act two, I’m going to look at juvenile ring members. So for this, I need to do a brief introduction to how decoy selection works. So let’s say that I have a whole bunch of blocks from 2017 up through 2019 and I want to spend some fund that is the green dot. My [wallet](https://www.getmonero.org/resources/moneropedia/wallet.html) is going to go out and pick a whole bunch of decoys, which are keys that do not belong to me but I grab the public key and I mix it in when I construct the signature. And so they’re going to take all of these - the true spend and the decoys - they’re going to mix them in the ring signature and then deposit the transaction as a new output. Now the only part that observers can see is this outside portion. They ostensibly don’t know what the true spend is. They can just see what went into the ring signature. And so one of the things you can do with that from an outside perspective is you can look at what is the youngest ring member between when the transaction was mined and then the youngest ring member. 

Just kind of hopping into it again, this is - thank you XMRChain, I scraped like 400,000 signatures. So most of them fall within a very young range. If we look at the three-month line, 99.7% of transactions have a very young youngest ring member. And then there is this weird outlier with 0.3% of transactions that use a different algorithm. So again, I’ve switched to a log-y scale so you can see a little bit more of what is going on. On the left, you see the correctly constructed transactions, and then on the right there's a couple of different anonymity pools. I’m not going to split them up here, but you can see that there are some odd things happening. 

Now one of the things that was interesting is that I was, wanted to look at, okay, well, we have a ten-block lock time, so the youngest ring member is going to be at least ten blocks because that's when you can spend your Monero. And then let’s see what the distribution looks like from there. Much to my surprise, there are people that are overriding the ten-block lock. That is, in the reference wallet, so the core software considers your funds unavailable until ten blocks - i.e., 20 minutes it has passed - 1.6% of transactions actually bypass that and have ring members that are even younger. This is going to be a very small anonymity pool. It’s a very kind of strange behavior. I looked through, again I scanned the transaction tree topology myself and a lot of the times you can see this again where you just see what hop every one or two blocks straight across. 

So there's a, oh-- switching to a heat map, I wanted to know, was this little spurt from a one-time event or is it constant? And what we see now, the x-axis is time, several weeks, and then the y-axis is, what was that youngest ring member? None of them should be less than ten. It should just be black below the time-line. And you see that throughout we have had people making these juvenile transactions. Here it is at the log scale. 

So my conclusions from these observations is that the vast majority of transactions - or the anonymity pool - follow this ten-block lock time that's in the reference wallet. A minority of ring signatures include members that are less than ten blocks old, which really sticks out. 

My philosophy is that protocol should enforce privacy-relevant reference issues. If it’s important enough that we code it into our wallet, we should also code it into our protocol. And so there's three options here. One is that we add that ten-block lock at the protocol level. So we would reject transactions that are younger than that. Another option to make it match would be to remove the ten-block lock in the reference wallet. Or there could be some compromise where we go to, say, five blocks but it’s also enforced in the protocol. My inclination right now is number one because there has not been research showing that lowering the confirmation time is safe, so that would be my conservative recommendation. 

Oh, earlier today I actually had a fourth option:  which was, what was it? Oh yes that we could, thank you, that we could keep the transactions that have juvenile ring members in the mem pool and not mine them until enough time has passed. That would be good for someone doing retrospective blockchain analysis. It would not be robust against an adversary that's running in our [inaudible] network. Oh, and a quick note: this is unrelated to buyers permitting zero-confirmation purchases. If you buy a t-shirt from me and I’m like, cool, five bucks -I’m not worried and walk away. That’s fine. That has nothing to do with protocol. 

Quick note: I think that ten blocks was chosen arbitrarily. Is this optimal? I’m not sure. Out of scope of with this talk. Let’s research it. 

Act three, is egregious decoy selection. So the standard best practice for selecting your decoys is to pick several of them from recently, and then you have kind of a couple longer ones further out. And the logic behind this is that most transactions occur - we suspect, based on spend time analysis of other chains -  that most outputs kind of churn relatively quickly and so you also want your decoys to be relatively recent. And you also want some long tails so that if someone has to spend an old output, they have cover for that. 

So this is the right way to go. And it's really bad practice to use uniform random decoy selection. So if I just pick 11 random members over the course of history. So kind of get a mental image of this, green dots are good, red dots are bad. 

Great. Okay, it’s quiz time: Who thinks A was generated correctly? What about B, does that look right? What about C? What about D? Okay. Pretty much everyone got that. A and D are wrong - or generated with a  different algorithm - and B and C are regular. And my point here is that just because something is nondeterministic does not mean it is nonverifiable. You all just very intuitively did this. 

A quick way to kind of make a statistical metric out of this is the median is convenient, so in a set with 11 members, your median is going to be sixth oldest. And so if you look at the median on these, the ones that were generated correctly tend to have a median that's relatively close to today, and ones that were generated using uniform decoy selection they're typically much further out. Again not to scale - it is actually much more dramatic difference than this. So if we look at that median, back to what outside observers can analyze, median ring member age is the sixth ring. And I’m going to be using what I call the offset-corrected median age, and I’m going to ignore the length of time up to the first ring member. And that’s to [inaudible] delayed broadcast. I generate a transaction, I don’t have Internet access for a day, and then I broadcast it. So this is that offset is ignored, you can still do that. 

So let’s look at the offset-corrected median age. That’s the x-axis. Main thing we see is that because most people use the correct algorithm most of them are very short. 99% of people use the correct decoy selection algo. If I put a 500-day mark you can see that there are a couple people doing strange things out there. Once again, I won’t dig all the way into this, but you have the regular anonymity pool on the left, and you have several small anonymity puddles on the right. Just looking at it on a log-log scale, so now the median age and the counts are in log scale. This big bump is transactions that were generated using the correct algorithm. It’s pretty clear, I think, at this point, even just intuitively, which ones we could rule out as being kind of oddly generated. 

I really like heat maps - you may have noticed. So looking at how this evolves over time, the x-axis is height, again, equivalent to time. The y-axis is this kind of offset-corrected median metric. And just to put some guides on this, the bottom row is one day, one month, one year. And you can see that the kind of big yellow band in the middle is the main anonymity pool. You want your transactions to be in that anonymity pool. Anything that has a strange decoy selection, that’s out past a month, out past a year, is definitely not using the standard algorithm. So these ones out here that are 500 days old, very peculiar there are some other heuristics that opens up - so we want to avoid that. 

So the conclusions there, the vast majority are using a plausible distribution. Small anonymity puddles use distinctly irregular selection, often that’s uniform, but there could be other kind of wonky things going on. I believe the offset-corrected median is a robust method for identifying the worst offenders, which are the biggest privacy leaks - so these ones that are like 500 days old. 

My recommendation is that the consensus protocol could reject transactions whose offset-corrected median age is more than some threshold. In a very lenient threshold would be about 500 days, which is so absurd that it would never reject a properly constructed ring. We could actually, plausibly put a more strict standard, but I didn’t want to go down the rabbit hole of parameter selection during this talk - that’s a conversation we will have in the upcoming weeks and months. 

So well, let's move on from that. 

So then my closing thoughts, kind of high level. One, visualize your data, leverage your intuition. It’s really hard to stare at just a text dump, but if you can import it into Python, make a couple quick plots, you will have way more power in interpreting what you are looking at. So my advice to privacy protocol engineers is enforce necessary best practices in the consensus rules. Don’t just hope that all of devs match the perfect reference implementation. It’s a complicated thing. There’s a lot to get right, it’s easy to get stuff wrong, and it would be helpful if the protocol actually rejected things that were wrong to help wallet makers debug, troubleshoot, and get their wallets working correctly. Privacy coin software developers, try to match the reference wallet. And an approximation or a simplification like just grabbing random decoys can leak a surprising amount of information. It can be kind of insidious and you often don’t notice it until you visualize it.  

And then for users, use a community-vetted open source wallet. See the [Monero sidebar on reddit](https://www.reddit.com/r/Monero/). When in doubt use the core software from [getmonero](https://www.getmonero.org/downloads/). And if you are curious you can look at your transaction on a block explorer. I have actually done that if I'm trying a new piece of software, I’ll go take a peek at it and just look at myself. Did it use the correct algo? Did it set a normal fee? All of that. 

So in closing, first I want to thank [Insight](https://www.insightconsensus.com/). I run a professional training program there to help basically professional software engineers, academic researchers, and hackers transition into a full-time career in blockchain engineering. And they actually sponsored me to come out here. So thank you very much. If you would like to be in our next cohort, applications are open I think for another week. But we’ll be running a full session, hands on and in person, next September. And also, Noncesense Research Lab, all the supporters there, much appreciated. 

And now I will open to questions. There’s my e-mail. And all these slides and code will be available at [k2019.noncesense.org](https://github.com/noncesense-research-lab/Konferenco2019). I’ve uploaded the slides. I’m going to sanitize the code a little bit and then I’ll put that up in the next couple days. Thank you. 

Question from Audience: Hey I’m curious as to who you think the worst offenders are. Is it wallets, exchanges, miners? Who do you think is actually doing this weird decoy selection or confirmation time? 

Answer: Good question. I don’t have any definitive answers. So with regards to the fees, I could see that being a whole bunch of different parties. With regards to spending faster than ten blocks, I haven’t the faintest, I would imagine. So in the last couple of weeks were like the order of 10,000 transactions, so I don’t think it's one person or a very like smallest-- I don’t know if it's one of the, some website, some exchange. I actually don’t know why an exchange would need to bypass that - that wouldn’t make sense. So I’m not sure. I’ve been digging around just doing analysis from the blockchain perspective. I haven’t done any matching back to real-world entities yet. 

Thank you much. 


